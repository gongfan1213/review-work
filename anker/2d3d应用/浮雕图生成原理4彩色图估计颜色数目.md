### 2.1 彩色图估计颜色数目

利用肘部法则来确定聚类数目，该聚类数目也是分层数。

肘部法则（Elbow Method）是一种在聚类算法中确定最佳聚类数目的启发式方法，特别是在k-means聚类中使用。这种方法的核心思想是探索数据中聚类的数量与每个点到其聚类中心的平均距离之间的关系。

#### 如何应用肘部法则：

1. **计算误差值**：对于k-means聚类，该值通常是WCSS（Within-Cluster-Sum-of-Squares），即每个值与聚类质心的偏差平方和。对于每个点，计算它到其分配的中心的距离的平方，然后将所有的距离平方相加。

2. **多次运行聚类算法**：使用k=1,2,3,...,n作为要尝试的聚类数量，并为每个k值计算上述误差。

3. **画出误差值**：使用一个线性图来表示不同k值对应的误差值。

4. **查找“肘”点**：随着聚类数量的增加，误差值通常会减少。这是因为，当有更多的簇时，每个簇中的数据点更贴近其中心。然而，误差值的减少速率在某一点会大大减缓。这个点被称为“肘”，它对应的k值就是最佳的聚类数量。

通过以上步骤，可以利用肘部法则确定彩色图的最佳聚类数目，从而进行颜色信息的提取和分层。
### 2.1 彩色图估计颜色数目

利用肘部法则来确定聚类数目，该聚类数目也是分层数。

肘部法则（Elbow Method）是一种在聚类算法中确定最佳聚类数目的启发式方法，特别是在k-means聚类中使用。这种方法的核心思想是探索数据中聚类的数量与每个点到其聚类中心的平均距离之间的关系。

#### 如何应用肘部法则：

1. **计算误差值**：对于k-means聚类，该值通常是WCSS（Within-Cluster-Sum-of-Squares），即每个值与聚类质心的偏差平方和。对于每个点，计算它到其分配的中心的距离的平方，然后将所有的距离平方相加。

2. **多次运行聚类算法**：使用k=1,2,3,...,n作为要尝试的聚类数量，并为每个k值计算上述误差。

3. **画出误差值**：使用一个线性图来表示不同k值对应的误差值。

4. **查找“肘”点**：随着聚类数量的增加，误差值通常会减少。这是因为，当有更多的簇时，每个簇中的数据点更贴近其中心。然而，误差值的减少速率在某一点会大大减缓。这个点被称为“肘”，它对应的k值就是最佳的聚类数量。

#### 示例图解

可以观察到“肘”点大约在k=5或k=6，这意味着增加更多的簇并不会导致误差大幅度减少，所以k=5或k=6可能是一个好的选择。

### 2.2 彩色图聚类

确定完聚类数目后，使用k-means来进行聚类，提取聚类后每个簇的中心点，即为每个分层的颜色值。

```python
cv::kmeans(pixels, layer_num, labels,
           cv::TermCriteria(cv::TermCriteria::EPS + cv::TermCriteria::COUNT, 100, 0.1),
           5, cv::KMEANS_PP_CENTERS, centers);
```

通过以上步骤，可以利用肘部法则确定彩色图的最佳聚类数目，并使用k-means算法进行颜色聚类，提取每个分层的颜色信息。
### 2.2 彩色图聚类

确定完聚类数目后，使用k-means来进行聚类，提取聚类后每个簇的中心点，即为每个分层的颜色值。

#### 代码示例

```python
cv::kmeans(pixels, layer_num, labels,
           cv::TermCriteria(cv::TermCriteria::EPS + cv::TermCriteria::COUNT, 100, 0.1),
           5, cv::KMEANS_PP_CENTERS, centers);
```

#### 参数解释

1. **pixels**：
   - 输入数据的样本集。是一个浮点数矩阵，其中每一行是一个RGB像素打平后的向量（row*col, 3）。

2. **layer_num**：
   - 聚类的数量，即您要分组的集群数量。这是K-means中的“K”。

3. **labels**：
   - 输出参数。这是一个整数向量，存储每个样本的标签（即每个样本所属的集群索引）。

4. **cv::TermCriteria**：
   - 终止迭代的条件。这可以是以下三种之一，或者它们的组合：
     - `cv::TermCriteria::EPS`：集群中心在两次连续的迭代中的移动距离小于或等于这个EPS值，那么算法就会提前停止，不再继续迭代。
     - `cv::TermCriteria::MAX_ITER`（也称为`cv::TermCriteria::COUNT`）：在达到指定的最大迭代次数时，算法终止。
   - 在这里，两个条件都被设置为终止条件，其中迭代次数是100，epsilon是0.1。

5. **attempts = 5**：
   - 使用k-means算法进行的尝试次数。由于k-means可能会因初始化不同而收敛到不同的结果，因此进行多次尝试并选择最佳结果。

6. **cv::KMEANS_PP_CENTERS**：
   - 用于初始化中心的方法。这个特定的方法是K-means++的初始化方法，它是一个启发式方法，用于选择初始簇中心以加速收敛。另一种常见的选择是`cv::KMEANS_RANDOM_CENTERS`，它随机选择初始中心。
   - K-means++是通过一个特定的概率机制来“智能地”选择初始簇中心的。具体的过程是：
     1. 随机选择：首先，从数据点集合中随机选择一个数据点作为第一个簇中心。
     2. 计算距离：对于数据集中的每一个数据点，计算它到已选择的簇中心最近的那个中心的距离。记这个距离为D(x)。
     3. 选择下一个簇中心：选择一个新的数据点作为下一个簇中心，选择的概率与D(x)²成正比。这意味着一个数据点到已选簇中心的距离越远，它被选为新的簇中心的概率就越大。这一步确保了新的簇中心尽可能地远离已存在的簇中心。
     4. 重复：继续重复步骤2和3，直到选择了全部的k个簇中心。

7. **centers**：
   - 输出参数。这是一个浮点数矩阵，其中每一行代表一个集群中心。

### 2.3 模型分层

1. **对聚类中心排序**：
   - 首先对聚类中心按照簇数进行从小到大排序，将排序后的`color_range`转成灰度值`gray_range`，其大小为`(layer_num, 1)`。

2. **估算高度范围**：
   - 然后根据聚类的数目，先对每层高度范围进行大致预估。

3. **高度值排序**：
   - 因为每层颜色进行灰度转换后，得到的高度值需要按照实际高度进行排序。将`gray_range`转换成高度值`height_range`，并对序列进行快速排序，（`height_range[a] < height_range[b]`），输出`sorted_indices`排序下标序列，以便对`colors_range`和`height_range`进行重排序。

通过以上步骤，可以利用k-means算法进行颜色聚类，并提取每个分层的颜色信息，最终实现模型的分层上色。
### 2.3 模型分层

1. **对聚类中心排序**：
   - 首先对聚类中心按照簇数进行从小到大排序，将排序后的`color_range`转成灰度值`gray_range`，其大小为`(layer_num, 1)`。

2. **估算高度范围**：
   - 然后根据聚类的数目，先对每层高度范围进行大致预估。

3. **高度值排序**：
   - 因为每层颜色进行灰度转换后，得到的高度值需要按照实际高度进行排序。将`gray_range`转换成高度值`height_range`，并对序列进行快速排序，（`height_range[a] < height_range[b]`），输出`sorted_indices`排序下标序列，以便对`colors_range`和`height_range`进行重排序。

4. **调整高度范围**：
   - 通过上述步骤得到排序后的每层颜色对应的高度值，需要判断该高度值是否在第2步粗略计算的每层高度范围内，如果不在范围内的，需要进行上下限判断和替换。
   - 得到调整后的每层高度范围后，需要进行固定层高（0.2）的切层处理，输出每层层号序列，例如：
     - Height Ranges: [0, 0.75] [0.75, 1.52858] [1.52858, 2.25] [2.25, 3]
     - Layer Ranges: { [1, 4] [5, 8] [9, 12] [13, 15] }
   - 需要注意的是，对于`layer_ranges`下限进行向下取整，上限进行向上取整（除了最后一层的上限），同时调整受影响的相邻层。

### 2.4 模型上色

遍历模型每一个顶点，判断顶点处于哪个分层，赋予顶点相应的分层颜色。

### 3. 部分效果展示

| 生成mesh: 5.90373s | 生成减面mesh: 0.60542s | 提取分层信息: 3.0733s |
|--------------------|------------------------|-----------------------|
| 生成mesh: 5.61912s | 生成减面mesh: 0.664615s | 提取分层信息: 12.0707s |
| 生成mesh: 7.3308s  | 生成减面mesh: 0.75504s  | 提取分层信息: 13.0046s |

### 4. 总结

模型减面能够降低大约9倍的mesh生成速度，内存大小能够降低10倍，减面后的模型普遍在20-40MB之间，具体取决于模型面积。

### TODO

1. 优化提取颜色的准确性；
2. 优化确定聚类数目的方法；
3. 优化分层信息的处理速度；
4. 未来加入语义信息，去理解图像的“点睛之笔”，生成更真实的mesh模型。
