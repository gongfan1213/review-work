

**1. 结论优先 & 核心价值**

*   **结论/定位：** 目前的智能建模软件普遍没有结合3D打印来考虑场景应用。我们专注于在3D打印建模领域的某些特定场景来做功能，不做大而全的功能，做特定场景的智能创作和应用。
*   **核心价值：** 让建模更简单，突出产品特点：高速、高精、多色。

**建模流程对比：**

| 传统建模                                 | 智能建模                                 |
| :--------------------------------------- | :--------------------------------------- |
| 专业的软件 (3D Max, Blender, ZBrush)   | 在Web/APP上即可完成，无需专业软件，上手简单 |
| 较高的3D建模处理技巧                      | 无需掌握3D建模处理技巧，入门门槛低           |
| 流程复杂：找模型 -> 建模 -> 切片 -> 打印 | 一键打印，集成智能切片                       |

**以城市地理3D模型为例：**

*   **传统方式：**  需要建模师获取专业的地理软件，然后进行城市3D信息获取，在专业建模软件进行模型二次加工，加入底盘，进行模型黏贴等操作；过程需要复杂的专业软件和比较高超的建模技巧；单副3D城市画售价: $2,186
*   **智能创作：**  用户仅需要在提供的地图Playground页面进行区域选取，然后框选自己想打印的地理区域，自动生成带各种底盘样式的3D城市地图，用户可以简单选择底盘样式，结合我们M5C的高精度和高速度，然后一键快速打印。成本基本就是几美金的线材成本。

**1.2 一期核心功能点**

*   **3D创作平台:**
    *   模型库：
        *   模型搜索引擎
        *   推荐系统
        *   UGC模型
    *   多端渲染：
        *    Web端
            *   Babylon.js
        *   APP端
        *   H5
    *   2D-to-3D:
        *  3D浮雕
            * 彩色：丝网印刷浮雕
            * 单色：
                * 柱状图浮雕
                * 透光浮雕
                * 高精度：地理浮雕（城市3D浮雕，隐形3D浮雕）
        *   单张图片重建：
            *   3D立体模型
            *   Nerf：3D场景重建
        * 多张图片重建
        *   Text-to-3D
            *  Shape-E
    *    智能建模
    *   智能切片：
        *  APP
        *   云切片
    *    开放平台
        *   项目开源
        *

**技术领域及具体技术名称 (北斗七星):**

| 技术领域             | 具体技术名称                     | 技术指标                                                       |
| :------------------- | :------------------------------- | :------------------------------------------------------------- |
| 智能易用创作平台     | 丝网印刷浮雕                   | 提供单张图片转多色丝网印刷风格浮雕画能力                         |
|                      | 卡通数字人                       | 根据用户头像创作卡通人偶模型                                     |
|                      | 模型库/搜索引擎                   | 补充模型库资源，提供模型检索和智能推荐服务                         |
|                      | 城市地理3D浮雕                 | 提供用户根据所选城市进行3D浮雕创作能力                             |
|                      | 智能切片                       | 根据模型推荐定制化切片方案                                       |
|                      | 跨平台3D建模创作软件            | 支持移动端和Web端建模创作                                        |
|                      | 模版库                         | 根据用户主题推荐可自由组合的模版库                                 |
|                      | AI创作广泛场景                   | 范围更广泛，精度更高的场景应用                                   |
|                      | 开放平台                       | 开放云切片、模型库、AI生成等能力                                 |

**2. 数据方案**
3D模型领域数据普遍遵循CC4.0协议
**2.1 协议类型**

*   **Creative Commons 4.0 (知识共享许可协议):**

    *   知识共享许可协议（英语：Creative Commons license，或创用CC许可）是一种公共著作权许可协议，其允许按照多种需求分发受著作权保护的作品。一个作者可使用创作共享许可授予他人分享、使用，甚至创作派生作品的权利。

**署名**

自2004年以来，除CC0及变体外的所有许可协议都要求原作者署名。署名必须包含“至多的信息”。一般来说，这意味着：

*   包含任何著作权声明（如适用）。
*   引用作者的名字，网名或用户ID等。
*   引用作品的标题或名称（如适用），
*    引用作者的CC许可协议。
*   如果作品是一个派生作品或改编作品，除了以上几点外，还应该说明这是一个派生作品
*   KOKONI APP上使用thingiverse的开源模型
好的，以下是整理后的文字内容，按照逻辑结构分段，并概括要点：

**2.3 开源数据集下载**

*   **2.3.1 AWS推荐:**
    *   链接： `https://amazon-berkeley-objects.s3.amazonaws.com/index.html`
    *   遵循 **CC BY 4.0** 协议 (Creative Commons Attribution 4.0 International Public License)。 协议内容：
        *   **Attribution(署名):** 必须给予适当的署名，提供许可证的链接，并说明是否进行了更改。
        *   **No additional restrictions(没有额外的限制):**不得使用法律条款或技术措施，在法律上限制他人从事许可证允许的任何事情。

*   **2.3.2 其他开源数据集：**

    *   **ShapeNet:** 一个丰富标注的大规模点云数据集，包含55个常见物品类别和513000个三维模型。
    *   **PASCAL3D+:** 包含12个刚体分类，每一类超过3000个实例，并且包含了对应的ImageNet中每一类的图像。
    *   **Pix3D:** 从单张RGB图像的3D形状建模数据库。
    *   **PartNet:** 一个面向局部和全局3D模型理解的数据集，提供了多个物体类别的高分辨率3D模型和相应的层次结构注释。
    *  **ScanNet**: ScanNet是一个大规模室内场景3D扫描数据集，包含室内场景的RGB-D图像、3D点云和语义标签。
    *   **Objverse:** `https://objaverse.allenai.org/`

**3. 模型生成方案**

*   **3.1 智能灯 (模版库):**
    内置各种模板组件,方便用户进行模型组装.

*   **3.2 浮雕画技术 (2D-to-Relief):**

    *   **3.2.1 透光浮雕 (Lithophane):**

        *   需要背光，可以非常高清的还原照片细节，适合做夜灯。
        *   流程：上传图片 -> 提取灰度 -> 根据灰度的数值映射到高度 -> 构造基底 -> 生成模型
        *   提取灰度的方式:

            ```
            r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]
            gray = 0.2989 * r + 0.5870 * g + 0.1140 * b
            ```
             通过使用切片操作[:, :, 0]、[:, :, 1] 和[:, :, 2]，将RGB图像的红色通道、绿色通道和蓝色通道分别提取出来，分别存储在变量r、g和b中。然后利用灰度转换公式,得到灰度图像.

            这个公式是基于人眼对不同颜色通道的感知度不同而设计的。每个通道都乘以对应的权重，然后将它们相加，得到最终的灰度值。常用的权重值是 0.2989、0.5870 和 0.1140，它们反映了红、绿、蓝三个通道的亮度贡献程度。

            结果是将RGB图像转换为灰度图像，其中每个像素的值代表其亮度。灰度图像只有一个通道，可以用于简化图像处理任务或在不需要彩色信息的情况下节省存储空间。

    *   **3.2.2 凸浮雕画 (Relief Painting):**
        * 3.2.2.1.   3D模型转凸浮雕画: 3D模型天然具有深度信息，非常容易转成浮雕画。
          流程：上传3D模型->寻找对称轴->等比列切片->前半模型等比列缩放->加入底板->生成模型
  好的，以下是整理后的文字内容，按照逻辑结构分段，并概括要点：

**丝网印刷风格浮雕图**

*   流程: 原始图片 -> 深度图 -> 多层上色 -> 模型打印
*   **目前状态：**
    *   生成的浮雕从高度和线条分层后对比HueForge的基本一致，目前问题模型大小200M左右,HueForge生成的模型大概30M左右。 待解决点:
        1.  尝试下采样方法(效果损失)
        2.  Open3D从点云生成Mesh的方式
        3.  Mesh库生成stl模型大小太大的问题。
    *   目前30M的模型，用我们的切片软件差不多用了10分钟；拓竹的切片软件十几秒到几十秒左右；纹理效果好像也没有拓竹的清晰。

**灰度提取方案：**

(图片：详细的灰度图提取和浮雕生成流程，包括特征线提取、区域分层、基础表面生成、细节添加等)
(图片: 不同参数设置下的莲花浮雕效果)
根据ControlNet的语义分割提取深度和法线向量,进行深度提取。

**3.3 数字人技术 (3DMM)**

*   **DECA:**
    *   特点：单图片重建head model，速度快，但重建的head model效果较粗糙。
    *   DECA仅使用户外拍摄的训练图像来学习回归参数化的面部模型，并从单张面部图像中重建具有详细面部几何的3D头部。通过学习的重建细节的参数化，可以通过控制FLAME（head model库）的表情和下颌姿势参数来对细节重建进行动画化。 这样可以在保持个体特定细节不变的同时合成新的皱纹。
    *   为了获得对重建面部表情依赖性皱纹的控制，同时保留特定人的细节（即痣、毛孔、眉毛和表情无关的皱纹），特定人的细节和表情依赖性皱纹必须被拆开。该方法的关键贡献是新的细节一致性损失，它可以强制实现这种分离。

* **目前进展:**
    *   存在还存在问题:
        1.  发型还没有办法自动贴合上去
        2.  头部还有一些空洞没有闭合
    *  后续优化的方向: 卡通数字人

**3.4 3D建模技术**

*   **3.4.1 NeRF (2D-to-3D)**
    *   特点：重建效果较逼真，但速度很慢，需要多张不同视角下的重建目标图像。
    *   NeRF是当前最为火热的研究领域之一，效果非常惊艳，它要解决的问题就是给定一些拍摄的图，如何生成新的视角下的图。
    *  建模技术分类:
        * 重建
            * 单图片
            * 多图片
            * 视频建模
        * 生成
            * text-to-3D
    *   不同于传统的三维重建方法把场景表示为点云、网格、体素等显式的表达，它独辟蹊径，将场景建模成一个连续的5D辐射场隐式存储在神经网络中，只需输入稀疏的多角度带pose的图像训练得到一个神经辐射场模型，根据这个模型可以渲染出任意视角下的清晰的照片。 通俗来讲就是构造一个隐式的渲染流程，其输入是某个视角下发射的光线的位置o，方向d以及对应的坐标(x,y,z)，送入神经辐射场Fθ得到体密度和颜色，最后再通过体渲染得到最终的图像。
    好的，以下是整理后的文字内容，按照逻辑结构分段，并概括要点：

**基于NeRF的场景三维重建**

*   **领域:**
    *   背景
        *   NeRF原理
        *   体渲染概述
    *   数据集介绍
        *   常见新视角合成数据集：
            *   blender
            *   LLFF
            *   shapeNet
        *   常见三维重建数据集
            *   DTU
            *   tanks & temples
            *  ETH3D
            *    ScanNet
    *   应用场景:
        *    新视点合成
        *   物体精细重建
        *   城市大场景重建
        *   人体重建
        *   3D风格迁移

*   **NeRF代码开发相关:**
    *   colmap
    *   tinycudann
        *   cuda
        *   cuda算子 with pybinding
    *   Nerf开源框架:
        *   nerfstudio
        *  sdfstudio
    *   NerfAcc

*   **基于NeRF的场景重建代表性工作:**
    *   从采样提升重建精度：
        *   NeuS
        *   VolSDF
        *   NeuS2
        *   monoSDF
        *   DS-NeRF
        *    Geo-NeuS
        *   NeualWarp
    *   加速、提炼渲染质量方法:
        *   nerf++
        *   mip-NeRF
        *   mipNeRF360
        *   Instant-ngp
        *    merf
    *   大规模NeRF：
        *    with MLP
            * nerf-W
            *   mega-NeRF
            *   block-NeRF
            *   cityNeRF(BungeeeNeRF)
        *  with grid/feature plane
            *   GP-NeRF
            *    NeRF for Urban scenes
    *    text-to-Nerf:
        *   DreamFusion
        *   Magic3D

**3.4.2 房屋重建**

*   **3.4.2.1 房屋外表面重建**

    *   **1. 单图重建流程：**

        劣质矫正图片 -> 智能抠图 -> 智能去遮挡+补全 -> 风格迁移3D卡通化 -> 补矢量图 -> 单图3D重建 -> 后处理
    *   **2. 多图重建流程：**
        房屋0度、90度、180度,270度照片-> 智能抠图 -> 智能去遮挡+补全 -> 风格迁移3D卡通化 -> 补矢量图 ->多图3D重建 -> 后处理

    *   目前多图重建3D重建效果：（Tr3D）

*   **3.4.2.2 房屋周边**

    *   通过识别匹配模版

*   **3.4.2.2 室内空间重建**

    *   **1. AR:**
        *   测距：ARkit 内置支持测距的方法，基于LiDAR 传感器、视觉惯性测量（VIO）系统 `https://www.assysto.com/`
        *   识别：基于端侧部署yolov模型，训练相应产品图像，检测室内的产品、家具等。
        *   APP推理框架：目前在验证 tensorflow-lite, pytorch-mobile

    *   **2. 3D重建:**
        *    ARkit 的RoomPlan：`https://developer.apple.com/cn/augmented-reality/roomplan/`
    好的，以下是整理后的文字内容，按照逻辑结构分段，并概括要点：

**借助 RoomPlan 将周围环境引入你的 App**

*   与顾客互动, 简化工作流程：
    *   利用 RoomPlan 直接在你的 App（如房地产、电子商务或酒店类 App）中创建房间户型图，协助顾客做出更加周全的决策。这些扫描也可以是建筑和室内设计工作流程中的第一步，有助于简化概念性的探索和规划。
*   利用激光雷达进行实时扫描:
    *   你可以完全自定义 App 的用户体验和扫描引导，也可以充分利用内建辅导 UI 来优化扫描，借助视觉反馈来实时实现扫描进度，并利用玩具屋视觉化来显示房间内所有可识别的物体。
*    **参数表示:**
RoomPlan 输出 USD 或 USDZ 文件格式，其中包括房间内可识别的每一个组件的尺寸，如墙壁或橱柜，以及所检测到的家具类型等。 在导入到兼容 USDZ 的各种工具时，如 Cinema 4D、Shapr3D 或 AutoCAD，可以进一步调整每一个组件的尺寸和位置。

**3.4.3 Text-to-3D**

*   目前由文字到3D模型，存在两种路径：
    1.  使用"文生图-"模型+Nerf生成3D模型，比如使用 stable diffusion + controller 插件，生成多视角的2D图，再由Nerf形成3D建模。
    2.  使用文字生成3D模型 - 这一类模型往往是，文本到扩散模型和Nerf结合。其原理为，先通过文本到图像的扩散模型生成2D图，再通过Nerf将2D生成3D模型。

    *   流程图： text -> 文本到图像扩散模型/text-to-image模型 -> NeRF -> 3D模型
    *    Stable-difussion -> Nerf

**3.5 渲染技术**

*   **3.4.1 APP+Web**
    *   使用 WebGL 渲染
    *   H5 使用 Babylonjs 进行模型渲染，及常规的预览操作
    *   App 通过嵌入 H5 页面渲染；PC 端同理
    *  后台方案: 采用open3D作为3D处理方案;

**3.6.1 模型数据**
模型数据包含：来源，模型格式，成本

体现有检索数据

| 来源          | 网站地址                                                         | 总模型数量 | 下载数量 |
| ------------- | :----------------------------------------------------------- | :------- | :------- |
| 创想云        | `https://www.crealitycloud.cn/model-category`                | 免费模型3万+ | 3万+     |
| Thingiverse   | `https://www.thingiverse.com`                                | 100万+    | 13万+    |
| Abo           | `https://amazon-berkeley-objects.s3.amazonaws.com/index.html#` | 7900+   | 7900+   |
| objverse      | `https://objaverse.allenai.org/`                             | 80万+    | 1万+     |
| Printables   | `https://www.printables.com/model`                             | 42万+    |          |
|Cults 3d|	https://cults3d.com/|	|
|Sketchfab	|https://sketchfab.com/||
|Thangs|	https://thangs.com/||
|MyMiniFactory	|https://www.myminifactory.com/pages/explore||
|Creazilla	|https://creazilla.com/sections/3-3d-models|	8000+|
|GrabCAD|	https://grabcad.com/library#!|	570万+|
|PartCommunity	|https://b2b.partcommunity.com/community/partcloud/index_partcloud.html||
|DownloadFree3D|	https://downloadfree3d.com/category/3d-printing-models/||
|Youmagine|	https://www.youmagine.com/|	19000+|
|Most3D	|https://www.most3d.cn/models/?sort=new|13000+|

**3.6.2 模型检索**

*   向量数据库搭建中，可以通过文本搜模型，图片搜模型，模型搜模型
*   向量搜索服务开发中：
     *   向量检索技术方案概要设计

*   模型搜索网站示例：`https://www.3dfindit.com/zh-CN/`
*    **文本搜模型：**
用户通过输入关键词，在数据库中匹配模型名，给出结果
*   **2D搜索模型：**
Sketch Search: 模型库需要离线准备好模型的轮廓图,用户在线通过画出模型的素描风格轮廓,去匹配模型轮廓图,以达到检索模型的目的.
好的，以下是整理后的文字内容，按照逻辑结构分段，并概括要点：

**Photo Search (2D 图像搜索模型)**

*   开源库: `https://github.com/zddhub/opensse`
*   模型库需要离线准备好模型的轮廓图，用户在线上传图片，把用户的图片转为黑白图片，去匹配模型轮廓图，达到检索模型目的

**模型检索 (整体框架)**

*   **检索方式：**
    *   Text检索：
        *    输入：
            *   关键词
            *   条件（可选）： 来源、文件格式、是否免费、License
        *    输出：
            * 模型信息列表:
                *   模型名
                *   模型ID
                *   模型数量
                *  下载数量
                *  作者
                *  来源
                * 缩略图(url)
            *   其他：
                * 不同来源匹配模型数量
                * 不同文件格式匹配数量
                * 收费与免费匹配数量

        *    问题：搜索结果怎么排序
        *  方案：
            *   做成可配置，供业务侧选择

    *   2D检索：
        *   Sketch Search
        *    Photo Search
        *  参考： `https://www.3dfindit.com/zh-CN/`
    *   3D检索
        *   3D Shape Search
        *    参考：
            *   `https://lmn.jnj.publications/lmniro4.pdf`
            *   `https://www.cs.princeton.edu/~funk/tog03.pdf`

* **模型浏览**
    *   模型信息列表
        * 模型id
        * 类别
        * 下载数量
        * 作者
        * 来源
        * license
        * 描述信息
        * Tag
        * 来源url/模型url
        * 模型大小
    *   线材类型和颜色信息怎么获取
        *   外部模型本事展示,直接跳转来源网站即可
        * 内部模型上传时填写
    * 模型大小信息怎么获取:
        * 前端可获取到模型的大小
        * 模型上传后做检测模型大小

**3.7 模型推荐技术**

*   **推荐系统流程：**

    模型数据候选集（数十万、数百万） -> 召回通道 -> 待排序模型集合（几百） -> 排序模型 -> 推荐结果（几十个）

*   **召回通道：** 前期可以使用基于内容推荐和基于协同过滤推荐的方法
*   **排序模型:** 初期阶段可考虑使用机器学习进行预估用户对推荐结果的喜好程度，进行排序返回
*    **推荐系统架构:**
    * UML图包含:
        *   业务应用
            * 单品推荐
            * 类目推荐
            * 猜你喜欢
            * 个性化排行旁
            * 个性化消息
            * 其他推荐
        *    召回
            * 相似召回
            * 热门召回
            * 互补召回
            * 偏好召回
            * 兴趣召回
            * 关联规则
        *   计算排序
            * LR
            * GBDT
            * XGBoost
            * DL
        *   过滤展示
            * 打印过滤
            * 隔离展示
            * 曝光过滤
        *   数据分析
            * 用户画像
                * 用户属性
                * 用户偏好
                * 用户行为
                * 用户标签
            * 物品画像
                * 物品属性
                * 物品标签
                * 物品关系
                * 物品排名
            * 特征工程
                * 特征抽取
                * 特征分析
                * 特征加工

        * 数据分析
            * 用户维度数据
            * 模型维度数据
            * 用户行为数据
            * 其他数据
        *底层基础数据

**4. 平台方案**

*   **4.1 模型内容管理平台**
    *   3D模型内容平台
        *   模型抓取：来源，模型名称，分类，标签，下载次数，点赞次数
        *   模型存储：minio
        *   模型展示
        *   模型审核
        *   模型打标

*   服务地址：``

